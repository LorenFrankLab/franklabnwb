{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an NWB 2.0 File with Frank Lab data\n",
    "\n",
    "This notebook shows how to create an [Neurodata Without Borders: Neurophysiology (NWB:N)](https://neurodatawithoutborders.github.io/) file from publicly available Frank Lab data. We will create an NWB file storing one day of data from one animal, inlcluding both awake behaving and sleep epochs, using the [PyNWB](https://pynwb.readthedocs.io/en/latest/) API. You can think of the PyNWB API as a toolbox for working with NWB files in the Python programming language.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pynwb\n",
    "\n",
    "# General dependencies\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.interpolate as interpolate\n",
    "\n",
    "# Time\n",
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "\n",
    "# Helpers for parsing Frank Lab Matlab data\n",
    "import franklabnwb.nspike_helpers as ns \n",
    "\n",
    "# Frank Lab PyNWB extensions and extension-related helpers\n",
    "import franklabnwb.fl_extension as fle\n",
    "import franklabnwb.fl_extension_helpers as flh\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker\n",
    "mdates.rcParams.update({'date.autoformatter.microsecond': '%H:%M:%S.%f'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which data do you want to load?\n",
    "\n",
    "We will create an NWB file storing data from one experimental day for one animal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------\n",
    "# ~ ~ ~ ~ UPDATE THIS VARIABLE WITH THE PATH TO YOUR DATA ~ ~ ~ ~\n",
    "# -------\n",
    "# Path to your data directory (e.g. the directory called \"Bon\" downloaded from CRCNS)\n",
    "#data_dir = os.path.expanduser('~/Data/CRCNS/Bon')\n",
    "data_dir = '/data/mkarlsso/Bon'\n",
    "nwb_dir = data_dir + '/NWB/'\n",
    "assert(os.path.isdir(data_dir)), \"Data directory does not exist! Update path.\"\n",
    "\n",
    "# -------\n",
    "# You don't need to change these unless you are trying out other days or animals.\n",
    "# We recommend starting with animal 'Bon', day 4.\n",
    "# -------\n",
    "day = 4\n",
    "animal = 'Bon'\n",
    "\n",
    "# We don't know the exact date and time this experiment was actually conducted, so we use a placeholder date.\n",
    "dataset_zero_time = datetime(2006, 1, day, 12, 0, 0, tzinfo=tz.gettz('US/Pacific'))\n",
    "\n",
    "# Recording parameters needed for import:\n",
    "eeg_samprate = 1500.0 # Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the new NWBFile object\n",
    "\n",
    "The PyNWB API provides a set of easily-used functions that allow us to store our data in the\n",
    "appropriate places for eventually saving as a valid NWB file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbf = pynwb.NWBFile(\n",
    "           session_description='Frank Lab CRCNS data for animal {0}, day {1}'.format(animal, day),\n",
    "           identifier='{0}{1:04}'.format(animal, day),\n",
    "           session_start_time=dataset_zero_time,\n",
    "           file_create_date=datetime.now(tz.tzlocal()),\n",
    "           lab='Frank Laboratory',\n",
    "           experimenter='Mattias Karlsson',\n",
    "           institution='UCSF',\n",
    "           experiment_description='Tetrode recordings from behaving rat on W-Track and during sleep',\n",
    "           session_id='{0}{1:04}'.format(animal, day))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the subject information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime(1980, 1, 1, 1, tzinfo=tz.gettz('US/Pacific'))\n",
    "\n",
    "#change when NWB date_of_birth bug fixed\n",
    "#nwbf.subject = pynwb.file.Subject(date_of_birth=unknown_birth_date,\n",
    "nwbf.subject = pynwb.file.Subject(description='Long Evans Rat', \n",
    "                                  genotype='WT', \n",
    "                                  sex='M', \n",
    "                                  species='rat', \n",
    "                                  subject_id='Bond', \n",
    "                                  weight='unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process tetrodes metadata\n",
    "\n",
    "1. Each tetrode gets an [ElectrodeGroup](https://pynwb.readthedocs.io/en/latest/pynwb.ecephys.html#pynwb.ecephys.ElectrodeGroup), where we store metadata about the tetrode such a unique name and the region of the brain it's in. \n",
    "\n",
    "2. Each individual recording channel (i.e. each of the 4 tetrode channels) gets its own row in the top-level [NWBFile.electrodes](https://pynwb.readthedocs.io/en/latest/pynwb.file.html?highlight=epochs#pynwb.file.NWBFile.electrodes) table. Here we store metadata about the electrode such as its location/depth in the brain, and the tetrode that it is part of.  We use the [NWBFile.add_electrode()](https://pynwb.readthedocs.io/en/latest/pynwb.file.html#pynwb.file.NWBFile.add_electrode) method to add each channel. As with the NWBFile.epochs table, discussed above, this is a DynamicTable.\n",
    "\n",
    "3. Each tetrode gets an \"Electrode Table Region\", an instance of [DynamicTableRegion](https://pynwb.readthedocs.io/en/latest/pynwb.core.html?highlight=DynamicTableRegion#pynwb.core.DynamicTableRegion). This is just a slice into the [NWBFile.electrodes](https://pynwb.readthedocs.io/en/latest/pynwb.file.html?highlight=epochs#pynwb.file.NWBFile.electrodes) table selecting the channels that go with the tetrode. We use the [create_electrode_table_region()]() method to add each tetrode's Electrode Table Region.\n",
    "\n",
    "4. Since LFP is often taken from a subset of a tetrode's channels, we create an Electrode Table Region for each tetrode's LFP channles. For example, if LFP was taken from just the first channel of a tetrode, we would create an Electrode Table Region just pointing to that channel of the [NWBFile.electrodes](https://pynwb.readthedocs.io/en/latest/pynwb.file.html?highlight=epochs#pynwb.file.NWBFile.electrodes) table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse tetrodes metadata from the old Frank Lab Matlab files\n",
    "tetrode_metadata = ns.parse_franklab_tetrodes(data_dir, animal, day)\n",
    "\n",
    "# Represent our acquisition system with a 'Device' object\n",
    "recording_device = nwbf.create_device(name='NSpike acquisition system')\n",
    "\n",
    "# Four channels per tetrode by definition \n",
    "num_chan_per_tetrode = 4     \n",
    "\n",
    "# Initialize dictionaries to store the metadata\n",
    "tet_electrode_group = {}  # group for each tetrode\n",
    "tet_electrode_table_region = {}  # region for each tetrode (all channels)\n",
    "lfp_electrode_table_region = {}  # region for each tetrode's LFP channels\n",
    "\n",
    "chan_num = 0   # Incrementing channel number\n",
    "lfp_channels = list()\n",
    "for tet_num, tet in tetrode_metadata.items():\n",
    "    \n",
    "    # Define some metadata parameters\n",
    "    tetrode_name = \"%02d\" % (tet_num) \n",
    "    impedance = np.nan\n",
    "    filtering = 'unknown - likely 600Hz-6KHz'\n",
    "    location = ns.get_franklab_tet_location(tet)  # area/subarea in the brain\n",
    "    depth = ns.get_franklab_tet_depth(tet)  # depth in the brain\n",
    "    description = \"tetrode {tet_num} located in {location} on day {day}\".format(\n",
    "        tet_num=tet_num, location=location, day=day)\n",
    "    \n",
    "    # 1. Represent the tetrode in NWB as an ElectrodeGroup\n",
    "    tet_electrode_group[tet_num] = nwbf.create_electrode_group(name=tetrode_name,\n",
    "                                                               description=description,\n",
    "                                                               location=location,\n",
    "                                                               device=recording_device)\n",
    "    \n",
    "    # 2. Represent each channels of the tetrode as a row in the NWBFile.electrodes table.\n",
    "    #    We do not have x and y coordinates for electrodes, so we set to np.nan.\n",
    "    for i in range(num_chan_per_tetrode):\n",
    "            nwbf.add_electrode(x=np.nan,  \n",
    "                               y=np.nan,\n",
    "                               z=depth,\n",
    "                               imp=impedance,\n",
    "                               location=location,\n",
    "                               filtering=filtering,\n",
    "                               group=tet_electrode_group[tet_num],  # tetrode this electrode belongs to\n",
    "                               group_name=tet_electrode_group[tet_num].name,\n",
    "                               id=chan_num)\n",
    "            chan_num = chan_num + 1  # total number of channels processed so far across all tets\n",
    "            \n",
    "    # 3. Create an Electrode Table Region (slice into the electrodes table) for each tetrode\n",
    "    table_region_description = 'tetrode %d all channels' % tet_num\n",
    "    table_region_name = '%d' % tet_num\n",
    "    table_region_rows = list(range(chan_num - num_chan_per_tetrode, chan_num)) # rows of NWBFile.electrodes table\n",
    "    tet_electrode_table_region[tet_num] = nwbf.create_electrode_table_region(\n",
    "        region=table_region_rows,\n",
    "        description=table_region_description,\n",
    "        name=table_region_name)\n",
    "\n",
    "    # 4. Create an ElectrodeTableRegion for all LFP recordings\n",
    "    lfp_channels.append(chan_num - num_chan_per_tetrode)# Assume that LFP is taken from the first channel\n",
    "    \n",
    "table_region_description = 'tetrode LFP channels'  \n",
    "lfp_electrode_table_region = nwbf.create_electrode_table_region(\n",
    "    region=lfp_channels,\n",
    "    description=table_region_description,\n",
    "    name='electrodes')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize PyNWB objects for storing behavioral timeseries data\n",
    "\n",
    "PyNWB provides several datatypes for specific kinds of behavior data. This allows anyone using PyNWB to know what kinds of data are stored in which places in the PyNWB file. However, all of these are examples of timeseries data (i.e. data with assocaited timestamps). Here, we use the following:\n",
    "- spatial position (x/y) will be stored in a [Position](https://pynwb.readthedocs.io/en/latest/pynwb.behavior.html#pynwb.behavior.Position) object\n",
    "- head direction (angle) will be stored in a [CompassDirection](https://pynwb.readthedocs.io/en/latest/pynwb.behavior.html#pynwb.behavior.CompassDirection) object\n",
    "- speed (m/s) will be stored in a more general [BehavioralTimeSeries](https://pynwb.readthedocs.io/en/latest/pynwb.behavior.html#pynwb.behavior.BehavioralTimeSeries) object\n",
    "\n",
    "These objects will later be used to store the specified types of data, but for now they are empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = pynwb.behavior.Position(name='Position')\n",
    "head_dir = pynwb.behavior.CompassDirection(name='Head Direction')\n",
    "speed = pynwb.behavior.BehavioralTimeSeries(name='Speed')\n",
    "linpos = pynwb.behavior.BehavioralTimeSeries(name='Linearized Position')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_data = ns.parse_franklab_behavior_data(data_dir, animal, day)\n",
    "epoch_time_ivls = []\n",
    "time_idx, x_idx, y_idx, dir_idx, vel_idx = range(5)  # column ordering of the behavioral data matrix\n",
    "\n",
    "all_epochs_taskdata = ns.parse_franklab_task_data(data_dir, animal, day)\n",
    "\n",
    "#load the linear position data\n",
    "linpos_data = ns.parse_franklab_linpos_data(data_dir, animal, day)\n",
    "\n",
    "# Initialize empty arrays for behavior samples across all epochs\n",
    "pos_samples = np.zeros((0, 2)) # x/y positions (n x 2)\n",
    "dir_samples = np.array([])\n",
    "speed_samples = np.array([])\n",
    "behavior_timestamps = []  # behavior timestamps are shared except for linpos\n",
    "linpos_timestamps = []\n",
    "apparatus_dict = dict()\n",
    "statematrix_dict = dict()\n",
    "\n",
    "# Loop over each epoch of this day\n",
    "for epoch_num, epoch_data in behavior_data.items():\n",
    "    m_per_pixel = epoch_data['cmperpixel'][0,0]/100    # meters / pixel conversion factor\n",
    "    \n",
    "    \n",
    "    # Behavior samples for this epoch (position, head direction, speed)\n",
    "    epoch_pos_samples = epoch_data['data'][:, (x_idx, y_idx)] * m_per_pixel\n",
    "    epoch_dir_samples = epoch_data['data'][:, dir_idx]\n",
    "    epoch_speed_samples = epoch_data['data'][:, vel_idx] * m_per_pixel\n",
    "    \n",
    "    # Timestamps for this epoch (note that we convert timestamps to POSIX time)\n",
    "    epoch_timestamps = epoch_data['data'][:, time_idx] + dataset_zero_time.timestamp()\n",
    "    \n",
    "    # Add this epoch's data to the array   \n",
    "    pos_samples = np.concatenate((pos_samples, epoch_pos_samples), axis=0)\n",
    "    dir_samples = np.concatenate((dir_samples, epoch_dir_samples), axis=0)\n",
    "    speed_samples = np.concatenate((speed_samples, epoch_speed_samples), axis=0)\n",
    "    behavior_timestamps = np.concatenate((behavior_timestamps, epoch_timestamps), axis=0)\n",
    "    \n",
    "    # Store the times of epoch start and end. We will use these later to build the 'epochs' table\n",
    "    epoch_time_ivls.append([epoch_timestamps[0], epoch_timestamps[-1]])\n",
    "    \n",
    "\n",
    "    # parse the task information structure so we can determine the type of epoch we're in\n",
    "    task_data = all_epochs_taskdata[epoch_num]\n",
    "    if task_data['type'][0] == 'sleep':\n",
    "        if 'Sleep Box' not in apparatus_dict.keys():\n",
    "            # for sleep epochs we do not create an polygon, so we just create an empty apparatus object\n",
    "            apparatus_dict['Sleep Box'] = fle.Apparatus(name='Sleep Box'.format(epoch_num), nodes=[], edges=[])\n",
    "    else:\n",
    "        apparatus_name = task_data['environment'][0]\n",
    "        if apparatus_name not in apparatus_dict.keys():\n",
    "            apparatus_dict[apparatus_name] = flh.get_apparatus_from_linpos(linpos_data[epoch_num], \n",
    "                                                                           name=apparatus_name, \n",
    "                                                                           conversion=m_per_pixel)\n",
    "        # for non-sleep box epochs we also need to process the linear position from the statematrix element\n",
    "        statematrix = linpos_data[epoch_num]['statematrix']\n",
    "        # for each field in the statematrix we create a separate timeseries object, and here we first\n",
    "        # concatenate the data. There is probably a better way to do this. \n",
    "        for key in list(statematrix.keys()):\n",
    "            if key not in statematrix_dict:\n",
    "                statematrix_dict[key] = statematrix[key]\n",
    "            else:\n",
    "                np.concatenate((statematrix_dict[key], statematrix[key]), axis=0)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'Position' already exists in 'Position'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-314-32a736691e63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                \u001b[0mtimestamps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbehavior_timestamps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                reference_frame='corner of video frame')\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m head_dir.create_spatial_series(name='Head direction', \n",
      "\u001b[0;32m~/anaconda3/envs/default/lib/python3.6/site-packages/hdmf/utils.py\u001b[0m in \u001b[0;36mfunc_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m                         \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExceptionType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'args'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/default/lib/python3.6/site-packages/pynwb/core.py\u001b[0m in \u001b[0;36m_func\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmt_docval_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontainer_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mckwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/default/lib/python3.6/site-packages/hdmf/utils.py\u001b[0m in \u001b[0;36mfunc_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m                         \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExceptionType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'args'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/default/lib/python3.6/site-packages/pynwb/core.py\u001b[0m in \u001b[0;36m_func\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"'%s' already exists in '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m                 \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'Position' already exists in 'Position'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Add the across-epochs behavioral data to the PyNWB objects\n",
    "# See place_field_with_queries.ipynb for examples of how we query these for specific epochs\n",
    "position.create_spatial_series(name='Position', \n",
    "                               timestamps=behavior_timestamps, \n",
    "                               data=pos_samples, \n",
    "                               reference_frame='corner of video frame')\n",
    "\n",
    "head_dir.create_spatial_series(name='Head direction', \n",
    "                               timestamps=behavior_timestamps, \n",
    "                               data=dir_samples, \n",
    "                               reference_frame='0=direction of top of video frame; ' + \n",
    "                                   'positive values clockwise (need to confirm this)')\n",
    "\n",
    "speed.create_timeseries(name='Speed', \n",
    "                        timestamps=behavior_timestamps, \n",
    "                        data=speed_samples, \n",
    "                        unit='m/s', \n",
    "                        description='smoothed movement speed estimate')\n",
    "\n",
    "# add timeseries to linpos\n",
    "for key in statematrix_dict.keys():\n",
    "    if key == 'time':\n",
    "        continue\n",
    "    else:\n",
    "        linpos.create_timeseries(name=key, \n",
    "                                 timestamps=statematrix_dict['time'],\n",
    "                                 data = statematrix_dict[key],\n",
    "                                 description='linear position statematrix information')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Linearized Position <class 'pynwb.behavior.BehavioralTimeSeries'>\n",
       "Fields:\n",
       "  time_series: { headdir <class 'pynwb.base.TimeSeries'>,  lindist <class 'pynwb.base.TimeSeries'>,  linearDistanceToWells <class 'pynwb.base.TimeSeries'>,  linearVelocity <class 'pynwb.base.TimeSeries'>,  referenceWell <class 'pynwb.base.TimeSeries'>,  segmentHeadDirection <class 'pynwb.base.TimeSeries'>,  segmentIndex <class 'pynwb.base.TimeSeries'>,  traj <class 'pynwb.base.TimeSeries'>,  wellExitEnter <class 'pynwb.base.TimeSeries'> }"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a ProcessingModule for behavior data\n",
    "behav_mod = nwbf.create_processing_module(name='Behavior', \n",
    "                                          description='Behavioral data')\n",
    "\n",
    "# Add the position, head direction and speed data to the ProcessingModule\n",
    "behav_mod.add_data_interface(position)\n",
    "behav_mod.add_data_interface(head_dir)\n",
    "behav_mod.add_data_interface(speed)\n",
    "behav_mod.add_data_interface(linpos)\n",
    "\n",
    "# create a ProcessingModule for task data\n",
    "task_mod = nwbf.create_processing_module(name='Task', \n",
    "                                          description='Task data')\n",
    "\n",
    "\n",
    "# ---------\n",
    "# Add all three Apparatuses to the \"Behavior\" ProcessingModule\n",
    "# ---------\n",
    "task_mod.add_data_interface(sleep_box_apparatus)\n",
    "task_mod.add_data_interface(wtrack_A_apparatus)\n",
    "task_mod.add_data_interface(wtrack_B_apparatus)\n",
    "\n",
    "print(\"Note that our fl_extension.Apparatus objects are now in the Task ProcessingModule:\")\n",
    "print(nwbf.modules['Task'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the apparatus geometries from animal position data\n",
    "Accurately representing the geometry and topology of behavioral apparatuses (i.e. tracks, mazes, open fields, sleep boxes) is essential for interpreting our spatial data. Here, we estimate track geometry by visually inspecting the animal position records. At the top of this cell, hard-coded values are provided for animal 'Bon', day 4. For other animals and days, you might need to adjust these values based on the plots of position data on each apparatus.  \n",
    "\n",
    "In the next cell, we will incorporate these geometry coordinates into formal Frank Lab Apparatus objects (franklab.extensions.yaml)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store apparatuses as NWB Apparatus objects (Frank Lab extension)\n",
    "\n",
    "As shown above, we have three apparatuses: Sleep Box, W-track A, and W-track B. We represent each behavioral apparatus as a Frank Lab Apparatus (franklab.extensions.yaml), which uses a graph representation (i.e. nodes and edges) to represent the topology of a track. Each Node represents an important component of the apparatus:\n",
    "- PointNode represents a point with an x/y position (e.g. reward well, novel object)\n",
    "- SegmentNode represents a 1D line segment (e.g. linearized maze arm)\n",
    "- PolygonNode represents a 2D area (e.g. open field / non-linearizable area)\n",
    "\n",
    "Each Node object has a 'coords' field that describes its spatial geometry, which we found in the previous cell. Nodes sharing at least one coordinate can be represented as spatially connected by adding an Edge. For example, we can represent a reward well (PointNode) at the end of a linearized W-track arm (SegmentNode) by adding an Edge connecting those nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sleep Box': \n",
       " Sleep Box <class 'franklabnwb.fl_extension.Apparatus'>\n",
       " Fields:\n",
       "   edges: { }\n",
       "   nodes: { }, 'TrackB': \n",
       " TrackB <class 'franklabnwb.fl_extension.Apparatus'>\n",
       " Fields:\n",
       "   edges: { segment0<->segment1 <class 'franklabnwb.fl_extension.Edge'>,  segment0<->segment3 <class 'franklabnwb.fl_extension.Edge'>,  segment0<->well0 <class 'franklabnwb.fl_extension.Edge'>,  segment1<->segment2 <class 'franklabnwb.fl_extension.Edge'>,  segment1<->segment3 <class 'franklabnwb.fl_extension.Edge'>,  segment2<->well1 <class 'franklabnwb.fl_extension.Edge'>,  segment3<->segment4 <class 'franklabnwb.fl_extension.Edge'>,  segment4<->well2 <class 'franklabnwb.fl_extension.Edge'> }\n",
       "   nodes: { segment0 <class 'franklabnwb.fl_extension.SegmentNode'>,  segment1 <class 'franklabnwb.fl_extension.SegmentNode'>,  segment2 <class 'franklabnwb.fl_extension.SegmentNode'>,  segment3 <class 'franklabnwb.fl_extension.SegmentNode'>,  segment4 <class 'franklabnwb.fl_extension.SegmentNode'>,  well0 <class 'franklabnwb.fl_extension.PointNode'>,  well1 <class 'franklabnwb.fl_extension.PointNode'>,  well2 <class 'franklabnwb.fl_extension.PointNode'> }, 'TrackA': \n",
       " TrackA <class 'franklabnwb.fl_extension.Apparatus'>\n",
       " Fields:\n",
       "   edges: { segment0<->segment1 <class 'franklabnwb.fl_extension.Edge'>,  segment0<->segment3 <class 'franklabnwb.fl_extension.Edge'>,  segment0<->well0 <class 'franklabnwb.fl_extension.Edge'>,  segment1<->segment2 <class 'franklabnwb.fl_extension.Edge'>,  segment1<->segment3 <class 'franklabnwb.fl_extension.Edge'>,  segment2<->well1 <class 'franklabnwb.fl_extension.Edge'>,  segment3<->segment4 <class 'franklabnwb.fl_extension.Edge'>,  segment4<->well2 <class 'franklabnwb.fl_extension.Edge'> }\n",
       "   nodes: { segment0 <class 'franklabnwb.fl_extension.SegmentNode'>,  segment1 <class 'franklabnwb.fl_extension.SegmentNode'>,  segment2 <class 'franklabnwb.fl_extension.SegmentNode'>,  segment3 <class 'franklabnwb.fl_extension.SegmentNode'>,  segment4 <class 'franklabnwb.fl_extension.SegmentNode'>,  well0 <class 'franklabnwb.fl_extension.PointNode'>,  well1 <class 'franklabnwb.fl_extension.PointNode'>,  well2 <class 'franklabnwb.fl_extension.PointNode'> }}"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apparatus_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# load the task information\n",
    "all_epochs_taskdata = ns.parse_franklab_task_data(data_dir, animal, day)\n",
    "apparatus_dict = dict()\n",
    "for epoch_num in all_epochs_taskdata.keys():\n",
    "    \n",
    "    # parse the task information structure\n",
    "    task_data = all_epochs_taskdata[epoch_num]\n",
    "\n",
    "    # create the necessary apparati. \n",
    "    # NOTE that in reality the same track has slightly different linear coordinates in each epoch, \n",
    "    # but for simplicity we only take the one from the first epoch for each track. As we are also saving the\n",
    "    # linearized position this should be okay.\n",
    "    if task_data['type'][0] == 'sleep':\n",
    "        if 'Sleep Box' not in apparatus_dict.keys():\n",
    "            # for sleep epochs we do not create an polygon, so we just create an empty apparatus object\n",
    "            apparatus_dict['Sleep Box'] = fle.Apparatus(name='Sleep Box'.format(epoch_num), nodes=[], edges=[])\n",
    "    else:\n",
    "        apparatus_name = task_data['environment'][0]\n",
    "        if apparatus_name not in apparatus_dict.keys():\n",
    "            apparatus_dict[apparatus_name] = flh.get_apparatus_from_linpos(linpos_data[epoch_num], \n",
    "                                                                           name=apparatus_name, \n",
    "                                                                           conversion=m_per_pixel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the Apparatuses in the NWBFile object\n",
    "\n",
    "After building the Apparatus objects, we store them in the \"Behavior\" [ProcessingModule](https://pynwb.readthedocs.io/en/latest/pynwb.base.html#pynwb.base.ProcessingModule), just like we did with the other behavioral data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ProcessingModule for apparatus data\n",
    "apparatus_mod = nwbf.create_processing_module(name='Apparatus', \n",
    "                                          description='Apparatus data')\n",
    "\n",
    "task_mod = nwbf.create_processing_module(name='Task', \n",
    "                                          description='Task data')\n",
    "# ---------\n",
    "# Add all  Apparatuses to the \"Behavior\" ProcessingModule\n",
    "# ---------\n",
    "for apparatus in apparatus_dict:\n",
    "    task_mod.add_data_interface(apparatus_dict[apparatus])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Represent behavioral tasks using Frank Lab NWB extension\n",
    "We also represent each behavioral task that the animal may perform on an apparatus as a Frank Lab Task (franklab.extensions.yaml). This object simply contains a name and a detailed description of the task. For the dataset here, we only have two tasks: W-Alternation and Sleep.\n",
    "\n",
    "We then store Task objects in the \"Behavior\" [ProcessingModule](https://pynwb.readthedocs.io/en/latest/pynwb.base.html#pynwb.base.ProcessingModule), just like we did with the other behavioral data above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note that we've added fl_extension.Task objects to our ProcessingModule:\n",
      "\n",
      "Task <class 'pynwb.base.ProcessingModule'>\n",
      "Fields:\n",
      "  data_interfaces: { Sleep <class 'franklabnwb.fl_extension.Task'>,  Sleep Box <class 'franklabnwb.fl_extension.Apparatus'>,  TrackA <class 'franklabnwb.fl_extension.Apparatus'>,  TrackB <class 'franklabnwb.fl_extension.Apparatus'>,  W-Alternation <class 'franklabnwb.fl_extension.Task'> }\n",
      "  description: Task data\n",
      "\n",
      "\n",
      "W-Alternation <class 'franklabnwb.fl_extension.Task'>\n",
      "Fields:\n",
      "  description: The animal runs in an alternating W pattern between three neighboring arms of a maze.\n",
      "\n",
      "\n",
      "Sleep <class 'franklabnwb.fl_extension.Task'>\n",
      "Fields:\n",
      "  description: The animal sleeps or wanders freely around a small, empty box.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task_name = 'Sleep'\n",
    "description = 'The animal sleeps or wanders freely around a small, empty box.'\n",
    "task_mod.add_data_interface(fle.Task(name=task_name, description=description))\n",
    "\n",
    "task_name = 'W-Alternation'\n",
    "task_description = 'The animal runs in an alternating W pattern between three neighboring arms of a maze.'\n",
    "task_mod.add_data_interface(fle.Task(name=task_name, description=task_description))\n",
    "\n",
    "print(\"Note that we've added fl_extension.Task objects to our ProcessingModule:\")\n",
    "print(nwbf.modules['Task'])\n",
    "print(nwbf.modules['Task']['W-Alternation'])\n",
    "print(nwbf.modules['Task']['Sleep'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store epoch metadata in the NWBFile object\n",
    "We store information about different sections of a day's worth of experiments as Epochs in the top-level [NWBFile.epochs](https://pynwb.readthedocs.io/en/latest/pynwb.file.html?highlight=epochs#pynwb.file.NWBFile.epochs) table. By default, there are required columns for 'start_time', 'stop_time', and 'tags'. We add additional metadata columns for the epoch's Task, Apparatus, etc. using the [NWBFile.add_epoch_column()](https://pynwb.readthedocs.io/en/latest/pynwb.file.html#pynwb.file.NWBFile.add_epoch_column) method. After we have all of the metadata columns set up, we add each epoch as a new row of the table using the [NWBFile.add_epoch()](https://pynwb.readthedocs.io/en/latest/pynwb.file.html#pynwb.file.NWBFile.add_epoch) method.\n",
    "\n",
    "<i>Take a look under the PyNWB hood</i>:</br>\n",
    "Each epoch occurs in a discrete time interval defined by its start and stop times. As such, the [NWBFile.epochs](https://pynwb.readthedocs.io/en/latest/pynwb.file.html?highlight=epochs#pynwb.file.NWBFile.epochs) table is an instance of [TimeIntervals](https://pynwb.readthedocs.io/en/latest/pynwb.epoch.html?highlight=TimeIntervals#pynwb.epoch.TimeIntervals), which is itself an instance of [DynamicTable](https://pynwb.readthedocs.io/en/latest/pynwb.core.html#pynwb.core.DynamicTable). Later, we will store electrodes and clustered units in two other DynamicTables. One of the advantages of using DynamicTables is it allows for adding arbitrary columns without having to write an extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "column 'exposure' already exists in DynamicTable 'epochs'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-7d9e5c96da5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# By default, it has columns for 'start_time', 'stop_time', and 'tags'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# ---------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mnwbf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_epoch_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'exposure'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'number of exposures to this apparatus'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mnwbf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_epoch_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'behavioral task for this epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mnwbf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_epoch_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'apparatus'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'behavioral apparatus for this epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/default/lib/python3.6/site-packages/hdmf/utils.py\u001b[0m in \u001b[0;36mfunc_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m                         \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExceptionType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'args'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/default/lib/python3.6/site-packages/pynwb/file.py\u001b[0m in \u001b[0;36madd_epoch_column\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__check_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_tags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tags'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0mcall_docval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_epoch_metadata_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/default/lib/python3.6/site-packages/hdmf/utils.py\u001b[0m in \u001b[0;36mcall_docval_func\u001b[0;34m(func, kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcall_docval_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmt_docval_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/default/lib/python3.6/site-packages/hdmf/utils.py\u001b[0m in \u001b[0;36mfunc_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m                         \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExceptionType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparsed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'args'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/default/lib/python3.6/site-packages/pynwb/core.py\u001b[0m in \u001b[0;36madd_column\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__colids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"column '%s' already exists in DynamicTable '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0mckwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: column 'exposure' already exists in DynamicTable 'epochs'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# ---------\n",
    "# Load epochs metadata from the Frank Lab Matlab files\n",
    "# ---------\n",
    "all_epochs_metadata = ns.parse_franklab_task_data(data_dir, animal, day)\n",
    "\n",
    "# ---------\n",
    "# Add metadata columns to the NWBFile.epochs table\n",
    "# By default, it has columns for 'start_time', 'stop_time', and 'tags'.\n",
    "# ---------\n",
    "nwbf.add_epoch_column(name='exposure', description='number of exposures to this apparatus')\n",
    "nwbf.add_epoch_column(name='task', description='behavioral task for this epoch')\n",
    "nwbf.add_epoch_column(name='apparatus', description='behavioral apparatus for this epoch')\n",
    "\n",
    "# ---------\n",
    "# Iteratively add each epoch to the NWBFile.epochs table\n",
    "# ---------\n",
    "task_exposure_dict = dict()\n",
    "no_exposure_start_num = 1000000\n",
    "for epoch_num, epoch_metadata in all_epochs_metadata.items():\n",
    "    \n",
    "    # start and stop times were inferred from the behavior data earlier\n",
    "    epoch_start_time, epoch_stop_time = epoch_time_ivls[epoch_num-1]  \n",
    "    \n",
    "    # meter per pixel ratio is also in the behavior data\n",
    "    m_per_pixel = behavior_data[epoch_num]['cmperpixel'][0,0]/100  \n",
    "    \n",
    "    # Frank Lab Task (from the \"Task\" ProcessingModule)\n",
    "    epoch_task = flh.get_franklab_task(epoch_metadata, task_mod)\n",
    "    \n",
    "    # Frank Lab Apparatus (from the \"Task\" ProcessingModule)\n",
    "    epoch_apparatus = flh.get_franklab_apparatus(epoch_metadata, task_mod)\n",
    "    \n",
    "    epoch_exposure_num = ns.get_exposure_num(epoch_metadata)\n",
    "    # if this is -1then we'll replace it with something that starts at 1e6 so it's always a number\n",
    "    if epoch_exposure_num == -1:\n",
    "        # check to see if this is the first time that this task \n",
    "        if epoch_task in task_exposure_dict.keys():\n",
    "            task_exposure_dict[epoch_task] += 1\n",
    "            exposure = task_exposure_dict[epoch_task]\n",
    "        else:\n",
    "            task_exposure_dict[epoch_task] = no_exposure_start_num\n",
    "    # Required column 'tags'. We do not presently use this.\n",
    "    epoch_tags = ''\n",
    "    \n",
    "    # Add this epoch to the NWBFile.epochs table\n",
    "    # Note that task and apparatus are references to the \"Behavior\" ProcessingModule, \n",
    "    # so they will not be unnecessarily duplicated within the NWBFile\n",
    "    nwbf.add_epoch(start_time=epoch_start_time,\n",
    "                   stop_time=epoch_stop_time,\n",
    "                   exposure=epoch_exposure_num,\n",
    "                   task=epoch_task,\n",
    "                   apparatus=epoch_apparatus,\n",
    "                   tags=epoch_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is an example epoch from the table.\n",
      "Note that the 'task' and 'apparatus' columns point to our Frank Lab extension objects.\n",
      "\n",
      "start_time                                          1.13641e+09\n",
      "stop_time                                           1.13641e+09\n",
      "exposure                                                     NA\n",
      "task          \\nSleep <class 'franklabnwb.fl_extension.Task'...\n",
      "apparatus     \\nSleep Box <class 'franklabnwb.fl_extension.A...\n",
      "tags                                                         []\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Here is an example epoch from the table.\\nNote that the 'task' and 'apparatus' columns point to our Frank Lab extension objects.\\n\")\n",
    "print(nwbf.epochs.to_dataframe().iloc[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the NWBFile\n",
    "We have now added many of the core features of Frank Lab data to the NWBFile. Note that we have not used all of the available top-level fields ('analysis', 'stimulus', etc). These fields can be used to store other kinds of data as necessary for your lab and analysis pipeline. However, it is not advised to store temporary or in-progress analyses in the NWBFile, as NWB is meant to store stable versions of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "root <class 'pynwb.file.NWBFile'>\n",
      "Fields:\n",
      "  acquisition: { LFP <class 'pynwb.ecephys.LFP'> }\n",
      "  analysis: { }\n",
      "  devices: { NSpike acquisition system <class 'pynwb.device.Device'> }\n",
      "  electrode_groups: { 01 <class 'pynwb.ecephys.ElectrodeGroup'>,  02 <class 'pynwb.ecephys.ElectrodeGroup'>,  03 <class 'pynwb.ecephys.ElectrodeGroup'>,  04 <class 'pynwb.ecephys.ElectrodeGroup'>,  05 <class 'pynwb.ecephys.ElectrodeGroup'>,  06 <class 'pynwb.ecephys.ElectrodeGroup'>,  07 <class 'pynwb.ecephys.ElectrodeGroup'>,  08 <class 'pynwb.ecephys.ElectrodeGroup'>,  10 <class 'pynwb.ecephys.ElectrodeGroup'>,  11 <class 'pynwb.ecephys.ElectrodeGroup'>,  12 <class 'pynwb.ecephys.ElectrodeGroup'>,  13 <class 'pynwb.ecephys.ElectrodeGroup'>,  14 <class 'pynwb.ecephys.ElectrodeGroup'>,  15 <class 'pynwb.ecephys.ElectrodeGroup'>,  17 <class 'pynwb.ecephys.ElectrodeGroup'>,  18 <class 'pynwb.ecephys.ElectrodeGroup'>,  19 <class 'pynwb.ecephys.ElectrodeGroup'>,  20 <class 'pynwb.ecephys.ElectrodeGroup'>,  21 <class 'pynwb.ecephys.ElectrodeGroup'>,  22 <class 'pynwb.ecephys.ElectrodeGroup'>,  23 <class 'pynwb.ecephys.ElectrodeGroup'>,  24 <class 'pynwb.ecephys.ElectrodeGroup'>,  25 <class 'pynwb.ecephys.ElectrodeGroup'>,  27 <class 'pynwb.ecephys.ElectrodeGroup'>,  28 <class 'pynwb.ecephys.ElectrodeGroup'>,  29 <class 'pynwb.ecephys.ElectrodeGroup'>,  30 <class 'pynwb.ecephys.ElectrodeGroup'> }\n",
      "  electrodes: electrodes <class 'pynwb.core.DynamicTable'>\n",
      "  epoch_tags: {}\n",
      "  epochs: epochs <class 'pynwb.epoch.TimeIntervals'>\n",
      "  experiment_description: Tetrode recordings from behaving rat on W-Track and during sleep\n",
      "  experimenter: Mattias Karlsson\n",
      "  ic_electrodes: { }\n",
      "  imaging_planes: { }\n",
      "  institution: UCSF\n",
      "  lab: Frank Laboratory\n",
      "  lab_meta_data: { }\n",
      "  modules: { Behavior <class 'pynwb.base.ProcessingModule'>,  Task <class 'pynwb.base.ProcessingModule'> }\n",
      "  ogen_sites: { }\n",
      "  session_id: Bon0004\n",
      "  stimulus: { }\n",
      "  stimulus_template: { }\n",
      "  subject: subject <class 'pynwb.file.Subject'>\n",
      "  time_intervals: { }\n",
      "  units: units <class 'pynwb.misc.Units'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(nwbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the NWBFile to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote NWB file: /data/mkarlsso/Bon/NWB/bon04.nwb\n"
     ]
    }
   ],
   "source": [
    "nwb_filename = \"{0}{1}{2:02}.nwb\".format(nwb_dir, animal.lower(), day)\n",
    "with pynwb.NWBHDF5IO(nwb_filename, mode='w') as iow:\n",
    "    iow.write(nwbf)\n",
    "print('Successfully wrote NWB file: ' + nwb_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read our NWBFile from disk to test round-trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "root <class 'pynwb.file.NWBFile'>\n",
      "Fields:\n",
      "  acquisition: { LFP <class 'pynwb.ecephys.LFP'> }\n",
      "  analysis: { }\n",
      "  devices: { NSpike acquisition system <class 'pynwb.device.Device'> }\n",
      "  electrode_groups: { 01 <class 'pynwb.ecephys.ElectrodeGroup'>,  02 <class 'pynwb.ecephys.ElectrodeGroup'>,  03 <class 'pynwb.ecephys.ElectrodeGroup'>,  04 <class 'pynwb.ecephys.ElectrodeGroup'>,  05 <class 'pynwb.ecephys.ElectrodeGroup'>,  06 <class 'pynwb.ecephys.ElectrodeGroup'>,  07 <class 'pynwb.ecephys.ElectrodeGroup'>,  08 <class 'pynwb.ecephys.ElectrodeGroup'>,  10 <class 'pynwb.ecephys.ElectrodeGroup'>,  11 <class 'pynwb.ecephys.ElectrodeGroup'>,  12 <class 'pynwb.ecephys.ElectrodeGroup'>,  13 <class 'pynwb.ecephys.ElectrodeGroup'>,  14 <class 'pynwb.ecephys.ElectrodeGroup'>,  15 <class 'pynwb.ecephys.ElectrodeGroup'>,  17 <class 'pynwb.ecephys.ElectrodeGroup'>,  18 <class 'pynwb.ecephys.ElectrodeGroup'>,  19 <class 'pynwb.ecephys.ElectrodeGroup'>,  20 <class 'pynwb.ecephys.ElectrodeGroup'>,  21 <class 'pynwb.ecephys.ElectrodeGroup'>,  22 <class 'pynwb.ecephys.ElectrodeGroup'>,  23 <class 'pynwb.ecephys.ElectrodeGroup'>,  24 <class 'pynwb.ecephys.ElectrodeGroup'>,  25 <class 'pynwb.ecephys.ElectrodeGroup'>,  27 <class 'pynwb.ecephys.ElectrodeGroup'>,  28 <class 'pynwb.ecephys.ElectrodeGroup'>,  29 <class 'pynwb.ecephys.ElectrodeGroup'>,  30 <class 'pynwb.ecephys.ElectrodeGroup'> }\n",
      "  electrodes: electrodes <class 'pynwb.core.DynamicTable'>\n",
      "  epoch_tags: {}\n",
      "  epochs: epochs <class 'pynwb.epoch.TimeIntervals'>\n",
      "  experiment_description: Tetrode recordings from rat during rest and task performance\n",
      "  experimenter: FrankLab Anonymous\n",
      "  ic_electrodes: { }\n",
      "  imaging_planes: { }\n",
      "  institution: UCSF\n",
      "  lab: Frank Laboratory\n",
      "  lab_meta_data: { }\n",
      "  modules: { Apparatus <class 'pynwb.base.ProcessingModule'>,  Behavior <class 'pynwb.base.ProcessingModule'>,  Task <class 'pynwb.base.ProcessingModule'> }\n",
      "  ogen_sites: { }\n",
      "  session_id: Bon0004\n",
      "  stimulus: { }\n",
      "  stimulus_template: { }\n",
      "  subject: subject <class 'pynwb.file.Subject'>\n",
      "  time_intervals: { }\n",
      "  units: units <class 'pynwb.misc.Units'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with pynwb.NWBHDF5IO(nwb_filename, mode='r') as ior:\n",
    "    nwbf_read = ior.read()\n",
    "    print(nwbf_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/mkarlsso/Bon/NWB/bon04.nwb'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nwb_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = behav_mod.data_interfaces['Position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Position': \n",
       " Position <class 'pynwb.behavior.SpatialSeries'>\n",
       " Fields:\n",
       "   comments: no comments\n",
       "   conversion: 1.0\n",
       "   data: [[0.3931875 0.351    ]\n",
       "  [0.3965625 0.3493125]\n",
       "  [0.3965625 0.3493125]\n",
       "  ...\n",
       "  [0.4303125 0.3645   ]\n",
       "  [0.4303125 0.3628125]\n",
       "  [0.4303125 0.3645   ]]\n",
       "   description: no description\n",
       "   interval: 1\n",
       "   num_samples: 214497\n",
       "   reference_frame: corner of video frame\n",
       "   resolution: 0.0\n",
       "   timestamps: [1.13640581e+09 1.13640581e+09 1.13640581e+09 ... 1.13641415e+09\n",
       "  1.13641415e+09 1.13641415e+09]\n",
       "   timestamps_unit: Seconds\n",
       "   unit: meters}"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.spatial_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "          epochs = nwbf.epochs.to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'numpy.uint8'>\n",
      "<class 'str'>\n",
      "<class 'numpy.uint8'>\n",
      "<class 'str'>\n",
      "<class 'numpy.uint8'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "          for enum in range(len(epochs)):\n",
    "               print(type(epochs['exposure'][enum]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdict = dict()\n",
    "testdict[task_mod] = task_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Task <class 'pynwb.base.ProcessingModule'>\n",
       "Fields:\n",
       "  data_interfaces: { Sleep <class 'franklabnwb.fl_extension.Task'>,  Sleep Box <class 'franklabnwb.fl_extension.Apparatus'>,  W-Alternation <class 'franklabnwb.fl_extension.Task'>,  W-track A <class 'franklabnwb.fl_extension.Apparatus'>,  W-track B <class 'franklabnwb.fl_extension.Apparatus'> }\n",
       "  description: Task data"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdict[task_mod]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.empty((0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.asarray([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.asarray([2 , 3])\n",
    "d = np.asarray([4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-339-d19000c5113e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/default/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all input arrays must have the same shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "c = np.stack((z,a,b,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
